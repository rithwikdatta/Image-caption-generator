{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import collections\n",
    "from PIL import Image\n",
    "from textwrap import wrap\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Embedding, LSTM, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(desc, stopwords):\n",
    "\n",
    "  cleaned = desc.lower()\n",
    "  cleaned = re.sub('[^a-z]',' ',cleaned)\n",
    "  tokens = cleaned.split(' ')\n",
    "  cleaned = ' '.join([w for w in tokens if w not in stopwords and len(w)>1])\n",
    "  \n",
    "  return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(dictionary):\n",
    "  vocab = set()\n",
    "\n",
    "  for desc_list in dictionary.values():\n",
    "    for desc in desc_list:\n",
    "      words = desc.split(' ')\n",
    "      for word in words:\n",
    "        vocab.add(word)\n",
    "\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\Rithwik Datta\\\\ML\\\\majorproject\\\\Flickr8k.token.txt', 'r') as f:\n",
    "  all_desc = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['is', 'an', 'a', 'the', 'was']\n",
    "all_dict = dict()\n",
    "\n",
    "for desc in all_desc:\n",
    "  if len(desc) < 1:\n",
    "    continue\n",
    "  file_name, file_desc = desc.split('\\t')[0].split('.')[0], desc.split('\\t')[1]\n",
    "  \n",
    "  if file_name not in all_dict.keys():\n",
    "    all_dict[file_name] = []\n",
    "\n",
    "  cleaned_desc = clean_description(file_desc, stopwords)\n",
    "  cleaned_desc = 'startseq ' + cleaned_desc + ' endseq'\n",
    "\n",
    "  all_dict[file_name].append(cleaned_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = get_vocabulary(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent_list = [item.strip('startseq').strip('endseq').strip(' ') for sublist in list(all_dict.values()) for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent_len = [len(sent) for sent in all_sent_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_len = int(np.mean([len(sentence.split()) for sentence in all_sent_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for a in all_sent_list for w in a.split(' ')]\n",
    "counts = collections.Counter(words)\n",
    "most_common = counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keys = [tupl[0] for tupl in most_common][:15]\n",
    "values = [tupl[1] for tupl in most_common][:15]\n",
    "lengths = set()\n",
    "for cap_list in all_dict.values():\n",
    "  lengths.add(len(cap_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcep = Xception(include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rithwik\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643cd1e54f644681b39368c93a2f50e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = dict()\n",
    "\n",
    "for dirpath, dirname, files in os.walk('Images'):\n",
    "  for filename in tqdm(files):\n",
    "    img_path = os.path.join(dirpath, filename)\n",
    "    if os.path.isfile(img_path):\n",
    "      img = Image.open(img_path)\n",
    "      img = img.resize((299,299))\n",
    "      img = np.expand_dims(img, axis=0)\n",
    "      img = img/127.5\n",
    "      img = img - 1.0\n",
    "\n",
    "      predictions[filename.split('.')[0]] = xcep.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47340968, 0.01730898, 0.07334232, ..., 0.08557959, 0.02102299,\n",
       "        0.23765522]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.get(list(predictions.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(dictionary):\n",
    "  final_list = []\n",
    "\n",
    "  for desc_list in dictionary.values():\n",
    "    for desc in desc_list:\n",
    "      final_list.append(desc)\n",
    "\n",
    "  return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tokenizer(dictionary):\n",
    "  desc_list = create_list(dictionary)\n",
    "  tokenizer = Tokenizer()\n",
    "  tokenizer.fit_on_texts(desc_list)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_input(tokens, pos, im_name, max_len, vocab_len, tokenizer, img_predictions):\n",
    "\n",
    "  inp = tokens[:pos]\n",
    "  out = tokens[pos]\n",
    "  inp = pad_sequences(sequences=[inp], maxlen=max_len)[0]\n",
    "  out = to_categorical(y=[out], num_classes=vocab_len, dtype='bool')[0]\n",
    "  \n",
    "  return img_predictions.get(im_name)[0], inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all_to_input(dictionary, max_len, vocab_len, tokenizer, img_predictions):\n",
    "  \n",
    "  X_1 = list()\n",
    "  X_2 = list()\n",
    "  y = list()\n",
    "\n",
    "  for im_name, descriptions in tqdm(dictionary.items()):\n",
    "    if im_name in img_predictions.keys():\n",
    "      for desc in descriptions:\n",
    "          tokens = tokenizer.texts_to_sequences([desc])[0]\n",
    "          for i in range(1, len(tokens)):\n",
    "              _X_1, _X_2, _y = convert_to_input(tokens, i, im_name, max_len, vocab_len, tokenizer, img_predictions)\n",
    "              X_1.append(_X_1)\n",
    "              X_2.append(_X_2)\n",
    "              y.append(_y)\n",
    "  return np.array(X_1), np.array(X_2), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = fit_tokenizer(all_dict)\n",
    "vocab_len = len(tokenizer.index_word) + 1\n",
    "max_len = len(max(create_list(all_dict)))\n",
    "cnn_len = predictions[list(predictions.keys())[0]].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rithwik\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b286650a33e243c1a83cce01ba31709a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8092.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.93 GiB for an array with shape (384050, 2048) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-176c9c8bfd40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_all_to_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-4ec6c73f2431>\u001b[0m in \u001b[0;36mconvert_all_to_input\u001b[1;34m(dictionary, max_len, vocab_len, tokenizer, img_predictions)\u001b[0m\n\u001b[0;32m     14\u001b[0m               \u001b[0mX_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_X_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.93 GiB for an array with shape (384050, 2048) and data type float32"
     ]
    }
   ],
   "source": [
    "X_1, X_2, y = convert_all_to_input(all_dict, max_len, vocab_len, tokenizer, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_arrays(arrays, set_seed=-1):\n",
    "    assert all(len(arr) == len(arrays[0]) for arr in arrays)\n",
    "    seed = np.random.randint(0, 2**(32 - 1) - 1) if set_seed < 0 else set_seed\n",
    "\n",
    "    for arr in arrays:\n",
    "        rstate = np.random.RandomState(seed)\n",
    "        rstate.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_arrays([X_1, X_2, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(\"model.h5\",compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\t\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(model, tokenizer, photo, max_len):\n",
    "\t\n",
    "\tstart_text = 'startseq'\n",
    "\n",
    "\tfor i in range(max_len):\n",
    "\n",
    "\t\ttokens = tokenizer.texts_to_sequences([start_text])[0]\n",
    "\n",
    "\t\ttokens = pad_sequences([tokens], maxlen=max_len)\n",
    "\n",
    "\t\tpred = model.predict([photo, tokens], verbose=0)\n",
    "\n",
    "\t\tpred = np.argmax(pred)\n",
    "\n",
    "\t\tword = word_for_id(pred, tokenizer)\n",
    "\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tstart_text += ' ' + word\n",
    "\n",
    "\t\tif word == 'endseq':\n",
    "\t\t\tbreak\n",
    "\n",
    "\treturn start_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'E:\\\\ML subject\\\\basketball.png'\n",
    "img = Image.open(img_path)\n",
    "img2 = img.copy()\n",
    "img = img.resize((299,299))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = img/127.5\n",
    "img = img - 1.0\n",
    "pred = xcep.predict(img)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "caption1 = generate_desc(loaded_model, tokenizer, pred, 93)\n",
    "caption1 = caption.strip('startseq').strip('endseq')\n",
    "print(caption1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS \n",
    "import os\n",
    "text=caption1\n",
    "language='en'\n",
    "tld='co.in'\n",
    "speech = gTTS(text = text, lang = language, slow = False,tld='co.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save\n",
    "dictionary = {'hello':'world'}\n",
    "np.save('my_file.npy', dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dictionary = np.load('my_file.npy',allow_pickle='TRUE').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 'world'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
